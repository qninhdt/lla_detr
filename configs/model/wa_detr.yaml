_target_: models.wa_detr_module.WADETRModule

optimizer:
  lr: 0.0001
  lr_backbone: 0.00001
  lr_drop: 20
  lr_gamma: 0.1
  lr_linear_proj_mult: 0.1
  weight_decay: 0.0001

hybrid:
  k_one2many: 6
  lambda_one2many: 1.0

net:
  _target_: models.wa_detr.build

  num_classes: 12

  num_embeddings: 8

  # Variants of Deformable DETR
  with_box_refine: true
  two_stage: true

  # model parameters
  frozen_weights: null

  # backbone
  backbone: resnet50
  dilation: false
  position_embedding: sine # sine | learned
  position_embedding_scale: 6.28318530718 # 2 * pi
  num_feature_levels: 4

  # transformer
  enc_layers: 6
  dec_layers: 6
  dim_feedforward: 2048
  hidden_dim: 256
  dropout: 0.0
  nheads: 8
  num_queries_one2one: 300
  num_queries_one2many: 1500
  dec_n_points: 4
  enc_n_points: 4

  # trick
  mixed_selection: true
  look_forward_twice: true
  use_checkpoint: false

  # loss
  aux_loss: true

  # matcher
  set_cost_class: 2
  set_cost_bbox: 5
  set_cost_giou: 2

  # loss coefficients
  giou_loss_coef: 2
  bbox_loss_coef: 5
  cls_loss_coef: 2
  focal_alpha: 0.25

# compile model for faster training with pytorch 2.0
compile: false
